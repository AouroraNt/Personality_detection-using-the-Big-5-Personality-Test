{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import random\n",
    "from pprint import pprint\n",
    "import statistics\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stemmer = SnowballStemmer(\"dutch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will develop an LSTM (Long Short term Memory) Deep Learning model to predict the personality of a participant given a written essay. The model will use word2vec embedding to represent text as vectors so we can feed it to the model.<br>This notebook will be built respecting the following outline :<br>\n",
    "<ul>\n",
    "    <li>Loading the dataset</li>\n",
    "    <li>Feature Engineering</li>\n",
    "    <li>Data splitting</li>\n",
    "    <li>Data modeling</li>\n",
    "    <li>Personalities prediction</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_df = pd.read_csv(\"./data/clean_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>essay</th>\n",
       "      <th>personality</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extroversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>clean_essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>56610387</td>\n",
       "      <td>Het is niet enkel algemeen geweten, het is ook...</td>\n",
       "      <td>12-35-70-38-49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>enkel algemen gewet bewez bevind anno sted wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>12570386</td>\n",
       "      <td>Alweer reclame? En het programma is nog maar n...</td>\n",
       "      <td>84-83-64-69-55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>alwer reclam programma net begonn zin twijfel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>10289345</td>\n",
       "      <td>Van welvaartstoename tot psychische neerval\\n\\...</td>\n",
       "      <td>65-58-48-38-80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>welvaartstoenam psychisch neerval belgie stat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                              essay  \\\n",
       "200  56610387  Het is niet enkel algemeen geweten, het is ook...   \n",
       "413  12570386  Alweer reclame? En het programma is nog maar n...   \n",
       "77   10289345  Van welvaartstoename tot psychische neerval\\n\\...   \n",
       "\n",
       "        personality  Openness  Conscientiousness  Extroversion  Agreeableness  \\\n",
       "200  12-35-70-38-49         0                  0             1              0   \n",
       "413  84-83-64-69-55         1                  1             1              1   \n",
       "77   65-58-48-38-80         1                  1             0              0   \n",
       "\n",
       "     Neuroticism                                        clean_essay  \n",
       "200            0  enkel algemen gewet bewez bevind anno sted wei...  \n",
       "413            1  alwer reclam programma net begonn zin twijfel ...  \n",
       "77             1  welvaartstoenam psychisch neerval belgie stat ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a sample of the loaded dataset\n",
    "essays_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 470 entries, 0 to 469\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   user_id            470 non-null    int64 \n",
      " 1   essay              470 non-null    object\n",
      " 2   personality        470 non-null    object\n",
      " 3   Openness           470 non-null    int64 \n",
      " 4   Conscientiousness  470 non-null    int64 \n",
      " 5   Extroversion       470 non-null    int64 \n",
      " 6   Agreeableness      470 non-null    int64 \n",
      " 7   Neuroticism        470 non-null    int64 \n",
      " 8   clean_essay        470 non-null    object\n",
      "dtypes: int64(6), object(3)\n",
      "memory usage: 33.2+ KB\n"
     ]
    }
   ],
   "source": [
    "essays_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the table above, we have exactly 470 essay with a subset of personalities attached to it, with none null values.<br>Since the loaded dataset is already preprocessed in the SVM notebook, so there is no need to do that again, we will exploit directly the `clean_essay` document and the `personalities` features to build our LSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionaries and encode essays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of tokens we have in the essays corpus\n",
    "all_words = ' '.join(essays_df.clean_essay.tolist())\n",
    "\n",
    "# here we will count the words frequencies we have in the essays corpus\n",
    "word_counts = Counter(all_words.split())\n",
    "\n",
    "# sorted word list according to descending order. i.e biggest on at first position and so on\n",
    "word_list = sorted(word_counts, key = word_counts.get, reverse = True)\n",
    "\n",
    "# creating two dictionaries to map. word to index and map index to word.\n",
    "# example 1--> essay --> 1 --> word to index\n",
    "# example 2--> essay --> index to word\n",
    "word_to_index = {word:idx+1 for idx,word in enumerate(word_list)}\n",
    "index_to_word = {idx+1:word for idx,word in enumerate(word_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_to_index sample dict :\n",
      "\n",
      "{'gaybashingtr': 15325,\n",
      " 'gebruikt': 161,\n",
      " 'gerold': 12705,\n",
      " 'gesabotteeerd': 12554,\n",
      " 'ieder': 322,\n",
      " 'losstond': 13829,\n",
      " 'omschol': 4911,\n",
      " 'productiev': 15873,\n",
      " 'verdubbel': 7236,\n",
      " 'woordbegrip': 5380}\n",
      "\n",
      "index_to_word sample dict :\n",
      "\n",
      "{50: 'belangrijk',\n",
      " 59: 'bijvoorbeeld',\n",
      " 2519: 'opgegroeid',\n",
      " 5204: 'representatief',\n",
      " 6197: 'rub',\n",
      " 6373: 'stolt',\n",
      " 9065: 'stramien',\n",
      " 9196: 'fmri',\n",
      " 12713: 'prijkt',\n",
      " 14871: 'begrafeniskost'}\n"
     ]
    }
   ],
   "source": [
    "# let's see a sample of how our `word_to_index` and `index_to_word`\n",
    "print(\"word_to_index sample dict :\\n\")\n",
    "pprint(dict(random.sample(word_to_index.items(), 10)))\n",
    "print(\"\\nindex_to_word sample dict :\\n\")\n",
    "pprint(dict(random.sample(index_to_word.items(), 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding essays\n",
    "encoded_essays = [[word_to_index[word] for word in essay.split()] for essay in essays_df['clean_essay']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we gonna encode all the labels for all the big five personalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_OPN_labels = essays_df['Openness'].values\n",
    "encoded_CON_labels = essays_df['Conscientiousness'].values\n",
    "encoded_EXT_labels = essays_df['Extroversion'].values\n",
    "encoded_AGR_labels = essays_df['Agreeableness'].values\n",
    "encoded_NEU_labels = essays_df['Neuroticism'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking some logical assertions e.g length of essays should be equal to length of labels\n",
    "assert len(encoded_essays) == len(encoded_EXT_labels),\"Number of of encoded essays and encoded labels should be same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding essays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we need to do some sort of passing to our encoded essays in order to make all the essays of same length i.e padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2196, 1958, 1786, 1735, 1650, 1594, 1493, 1472, 1470, 1463, 1434, 1430, 1420, 1404, 1394, 1344, 1329, 1325, 1325, 1322]\n"
     ]
    }
   ],
   "source": [
    "# printing top 20 max length\n",
    "len_max = ([len(x) for x in encoded_essays])\n",
    "print(sorted(list(len_max), reverse=True)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in order to get the right padding from the list of essays mengths above, we will use the median statistical function to get that right padding value, and then we might add more space on it to make it hold sufficient tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median of the essays lengths distributions is 362.0\n"
     ]
    }
   ],
   "source": [
    "print(\"The median of the essays lengths distributions is {}\".format(statistics.median(len_max)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the median of essays length is 362 so a standard size of 400 should be enough to get all the features of an essay.\n",
    "also probably people will have expressed how they feel in their first 300 words. so lets fix a standard essay size of 400, in case if reviews are short we will pad zeros meanwhile and in case reviews are long we will truncate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pad our encoded essays/feature\n",
    "def pad_features(essays, max_length):\n",
    "    \"\"\"\n",
    "    Return features of reviews where each review is padded with 0's or truncted to the max_length\n",
    "    \"\"\"\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    # pad or truncate each review\n",
    "    for idx, row in enumerate(essays):\n",
    "        if len(row) >= max_length:\n",
    "            features.append(row[:max_length])\n",
    "        else:\n",
    "            features.append(np.concatenate((np.zeros(max_length-len(row)), np.array(row))))\n",
    "        \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 2., 3., 4.],\n",
       "       [1., 2., 3., 4., 5., 6., 7., 8.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a simple sanity check\n",
    "test_array = [[1,2,3,4],\n",
    "    [1,2,3,4,5,6,7,8,9,10]]\n",
    "\n",
    "# pad the test_array to a maximum size of 8\n",
    "pad_features(test_array,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are calling our essays features because it makes sense to call \n",
    "# it feature now as we will feed this feature to our model later\n",
    "padded_features = pad_features(essays = encoded_essays, max_length = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the number of feature is equal to number of reviews we passed\n",
    "assert len(padded_features) == len(encoded_essays),\"Length Mismatch after padding\"\n",
    "assert len(padded_features[0]) == 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total length of essays in my features which is 470\n",
    "total = padded_features.shape[0]\n",
    "# set the train size to 0.8\n",
    "train_ratio = 0.8\n",
    "\n",
    "# the plan is to use 80% of data for training and use remaining 20% for testing and validation\n",
    "# we will split the remaining 20% into half and seperate into testing and validation sets\n",
    "train_idx = int(total*0.8)\n",
    "train_x, remaining_x  = padded_features[:train_idx], padded_features[train_idx:]\n",
    "\n",
    "# doing the same for labels \n",
    "train_y_OPN, remaining_y_OPN = encoded_OPN_labels[:train_idx], encoded_OPN_labels[train_idx:]\n",
    "train_y_CON, remaining_y_CON = encoded_CON_labels[:train_idx], encoded_CON_labels[train_idx:]\n",
    "train_y_EXT, remaining_y_EXT = encoded_EXT_labels[:train_idx], encoded_EXT_labels[train_idx:]\n",
    "train_y_AGR, remaining_y_AGR = encoded_AGR_labels[:train_idx], encoded_AGR_labels[train_idx:]\n",
    "train_y_NEU, remaining_y_NEU = encoded_NEU_labels[:train_idx], encoded_NEU_labels[train_idx:]\n",
    "\n",
    "\n",
    "# splitting the remaining 20% to validation and testing\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "test_x, valid_x  = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "\n",
    "# doing the same for labels\n",
    "test_y_OPN, valid_y_OPN = remaining_y_OPN[:test_idx], remaining_y_OPN[test_idx:]\n",
    "test_y_CON, valid_y_CON = remaining_y_CON[:test_idx], remaining_y_CON[test_idx:]\n",
    "test_y_EXT, valid_y_EXT = remaining_y_EXT[:test_idx], remaining_y_EXT[test_idx:]\n",
    "test_y_AGR, valid_y_AGR = remaining_y_AGR[:test_idx], remaining_y_AGR[test_idx:]\n",
    "test_y_NEU, valid_y_NEU = remaining_y_NEU[:test_idx], remaining_y_NEU[test_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t Features Shape\n",
      "Train Set:\t\t(376, 400) \n",
      "Validation Set:\t\t(47, 400) \n",
      "Testing Set\t\t(47, 400)\n"
     ]
    }
   ],
   "source": [
    "# lets see the shape of our training, validation and testing data\n",
    "print(\"\\t\\t\\t Features Shape\")\n",
    "print(\"Train Set:\\t\\t{}\".format(train_x.shape),\n",
    "     \"\\nValidation Set:\\t\\t{}\".format(valid_x.shape),\n",
    "     \"\\nTesting Set\\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t Label Shape\n",
      "Train Set:\t\t(376,) \n",
      "Validation Set:\t\t(47,) \n",
      "Testing Set\t\t(47,)\n"
     ]
    }
   ],
   "source": [
    "#lets see the shape of labels for out training, validation and testing data\n",
    "print(\"\\t\\t\\t Label Shape\")\n",
    "print(\"Train Set:\\t\\t{}\".format(train_y_OPN.shape),\n",
    "     \"\\nValidation Set:\\t\\t{}\".format(valid_y_OPN.shape),\n",
    "     \"\\nTesting Set\\t\\t{}\".format(test_y_OPN.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data After preprocessing: \n",
      "Features:(470, 400)\n",
      "Labels:(470,)\n"
     ]
    }
   ],
   "source": [
    "print('Total data After preprocessing: \\nFeatures:{}\\nLabels:{}'.format(padded_features.shape, encoded_OPN_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset and batching into DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we will use TensorDataset and DataLoader for this purpose\n",
    "* TensorDataset takes Features and Labels with same dimension and creates a dataset\n",
    "* DataLoader makes our Dataset into generator that will give us both features and labels in batch sizes\n",
    "\n",
    "`train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))`\n",
    "\n",
    "`train_loader = DataLoader(train_data, batch_size=batch_size)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Openness prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TensorDatasets\n",
    "train_data_OPN = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y_OPN))\n",
    "valid_data_OPN = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y_OPN))\n",
    "test_data_OPN =  TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y_OPN))\n",
    "\n",
    "# set the batch size\n",
    "batch_size = 47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will shuffle the data because if we remember our data was like first 100 were Openness and the second 100 were not this might result in biasness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_OPN = DataLoader(train_data_OPN, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "valid_loader_OPN = DataLoader(valid_data_OPN, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "test_loader_OPN = DataLoader(test_data_OPN, shuffle=True, batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:torch.Size([47, 400])\n",
      "Sample Input:\n",
      "tensor([[1.6920e+03, 5.2000e+01, 3.6600e+02,  ..., 5.6100e+02, 5.3000e+01,\n",
      "         1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4200e+02, 9.6200e+02,\n",
      "         6.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5000e+01, 9.7000e+01,\n",
      "         4.9900e+02],\n",
      "        ...,\n",
      "        [1.5100e+02, 5.0000e+00, 3.9700e+02,  ..., 5.8000e+01, 3.0000e+00,\n",
      "         1.7700e+02],\n",
      "        [2.2000e+01, 1.0950e+03, 1.0950e+03,  ..., 1.4800e+02, 1.1969e+04,\n",
      "         2.2000e+01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.2500e+02, 1.0000e+01,\n",
      "         1.3020e+03]], dtype=torch.float64)\n",
      "\n",
      "Sample Label size:torch.Size([47])\n",
      "Sample Label:\n",
      "tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# lets visualize a batch of our training data\n",
    "dataiter = iter(train_loader_OPN)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size:{}'.format(sample_x.size()))\n",
    "print('Sample Input:\\n{}\\n'.format(sample_x))\n",
    "print('Sample Label size:{}'.format(sample_y.size()))\n",
    "print('Sample Label:\\n{}'.format(sample_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our LTSM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU\n"
     ]
    }
   ],
   "source": [
    "# checking if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "    print('Training on GPU')\n",
    "else:\n",
    "    print(\"Training on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class PersonalityLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(PersonalityLSTM, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the network\n",
    "\n",
    "Here, we'll instantiate the network. First up, defining the hyperparameters.\n",
    "\n",
    "* vocab_size: Size of our vocabulary or the range of values for our input, word tokens.\n",
    "* output_size: Size of our desired output; the number of class scores we want to output (1: Openness personality/ 0:otherwise).\n",
    "* embedding_dim: Number of columns in the embedding lookup table; size of our embeddings.\n",
    "* hidden_dim: Number of units in the hidden layers of our LSTM cells. Usually larger is better performance wise. * * Common values are 128, 256, 512, etc.\n",
    "* n_layers: Number of LSTM layers in the network. Typically between 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PersonalityLSTM(\n",
      "  (embedding): Embedding(20461, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate our model with hyper parameters\n",
    "\n",
    "vocab_size = len(word_to_index) + 2\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = PersonalityLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the learning rate to 0.001\n",
    "lr = 0.001\n",
    "\n",
    "# loss and optimization functions\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# save path to save our weights with best validation accuracy\n",
    "save_OPN_path = './models/best_validation_OPN.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "def train(model, criterion, optimizer, train_loader, valid_loader, batch_size, train_on_gpu, save_path):\n",
    "    valid_loss_min = np.Inf\n",
    "        \n",
    "    # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "    epochs = 4 \n",
    "\n",
    "    counter = 0\n",
    "    print_every = 10\n",
    "    clip=5 # gradient clipping\n",
    "\n",
    "    # move model to GPU, if available\n",
    "    if(train_on_gpu):\n",
    "        model.cuda()\n",
    "\n",
    "    model.train()\n",
    "    # train for some number of epochs\n",
    "    for e in range(epochs):\n",
    "        # initialize hidden state\n",
    "        h = model.init_hidden(batch_size)\n",
    "\n",
    "        # batch loop\n",
    "        for inputs, labels in train_loader:\n",
    "            counter += 1\n",
    "            if(train_on_gpu):\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # get the output from the model\n",
    "            output, h = model(inputs, h)\n",
    "\n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            # loss stats\n",
    "            if counter % print_every == 0:\n",
    "                # Get validation loss\n",
    "                val_h = net.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                net.eval()\n",
    "                \n",
    "                for inputs, labels in valid_loader:\n",
    "\n",
    "                    # Creating new variables for the hidden state, otherwise\n",
    "                    # we'd backprop through the entire training history\n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                    if(train_on_gpu):\n",
    "                        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                    output, val_h = model(inputs, val_h)\n",
    "                    val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                # lets save the model with best validation accuracy. \n",
    "                # It makes sense that we shouldnot need to train the model everytime.\n",
    "                if np.mean(val_losses) <= valid_loss_min:\n",
    "                    print('Validation loss decreased ({:.6f} ---------> {:.6f}).\\t Saving model...'.\n",
    "                          format(valid_loss_min, np.mean(val_losses)))\n",
    "                    torch.save(model.state_dict(), save_path)\n",
    "                    valid_loss_min = np.mean(val_losses)\n",
    "\n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf ---------> 0.694335).\t Saving model...\n",
      "Epoch: 2/4... Step: 10... Loss: 0.663769... Val Loss: 0.694335\n",
      "Epoch: 3/4... Step: 20... Loss: 0.450650... Val Loss: 0.697766\n",
      "Epoch: 4/4... Step: 30... Loss: 0.216449... Val Loss: 0.954250\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "train(model=net, criterion=criterion, optimizer=optimizer, train_loader=train_loader_OPN, valid_loader=valid_loader_OPN, batch_size=batch_size, train_on_gpu=train_on_gpu, save_path=save_OPN_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "net.load_state_dict(torch.load(save_OPN_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, test_loader, batch_size, train_on_gpu):\n",
    "    \"\"\"\n",
    "    Tests and returns the accuracy and loss of the given model on the given dataset\n",
    "    \"\"\"\n",
    "    test_losses = [] # track loss\n",
    "    num_correct = 0\n",
    "    \n",
    "    # init hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "    net.eval() # turning of back propagation\n",
    "    \n",
    "    #iterating over test data\n",
    "    for inputs, labels in test_loader:\n",
    "        # creating a new variable for the hidden state, othewise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            \n",
    "        #get predicted outputs\n",
    "        output, h = net(inputs, h)\n",
    "        \n",
    "        #calculate loss\n",
    "        test_loss = criterion(output.squeeze(), labels.float())\n",
    "        test_losses.append(test_loss.item())\n",
    "        \n",
    "        # convert the output probabilities to predicted class( 0 or 1)\n",
    "        pred = torch.round(output.squeeze()) # rounds to nearest integer\n",
    "        \n",
    "        # compare prediction to true label\n",
    "        correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "        num_correct += np.sum(correct)\n",
    "    \n",
    "    # printing stats\n",
    "    print('Test loss: {:.3f}'.format(np.mean(test_losses)))\n",
    "    \n",
    "    #accuracy over all test_data\n",
    "    test_acc = num_correct/len(test_loader.dataset)\n",
    "    print(\"Test accuracy: {:.3f} %\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.688\n",
      "Test accuracy: 0.574 %\n"
     ]
    }
   ],
   "source": [
    "# testing performance of our model\n",
    "test(model=net, criterion=criterion, test_loader=test_loader_OPN, batch_size=batch_size, train_on_gpu=train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Conscientiousness prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TensorDatasets\n",
    "train_data_CON = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y_CON))\n",
    "valid_data_CON = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y_CON))\n",
    "test_data_CON =  TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y_CON))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will shuffle the data because if we remember our data was like first 100 were Openness and the second 100 were not this might result in biasness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_CON = DataLoader(train_data_CON, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "valid_loader_CON = DataLoader(valid_data_CON, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "test_loader_CON = DataLoader(test_data_CON, shuffle=True, batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:torch.Size([47, 400])\n",
      "Sample Input:\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.6920e+03, 4.4850e+03,\n",
      "         3.4990e+03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 2.9400e+02,\n",
      "         1.7400e+02],\n",
      "        [3.4000e+01, 6.1000e+01, 2.2270e+03,  ..., 3.1000e+01, 4.8900e+02,\n",
      "         2.7000e+01],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5700e+02, 1.0200e+02,\n",
      "         4.1300e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1680e+03, 9.0000e+00,\n",
      "         4.5740e+03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 5.0000e+00,\n",
      "         1.6120e+03]], dtype=torch.float64)\n",
      "\n",
      "Sample Label size:torch.Size([47])\n",
      "Sample Label:\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# lets visualize a batch of our training data\n",
    "dataiter = iter(train_loader_CON)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size:{}'.format(sample_x.size()))\n",
    "print('Sample Input:\\n{}\\n'.format(sample_x))\n",
    "print('Sample Label size:{}'.format(sample_y.size()))\n",
    "print('Sample Label:\\n{}'.format(sample_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the LSTM model architecture is already built before, there is no need to repeat again, we gonna just call the same model within differenr dataset, which concerns this time the Conscientiousness personality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save path to save our weights with best validation accuracy\n",
    "save_CON_path = './models/best_validation_CON.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf ---------> 0.707953).\t Saving model...\n",
      "Epoch: 2/4... Step: 10... Loss: 0.701135... Val Loss: 0.707953\n",
      "Epoch: 3/4... Step: 20... Loss: 0.518467... Val Loss: 0.739995\n",
      "Epoch: 4/4... Step: 30... Loss: 0.301660... Val Loss: 0.915529\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "train(model=net, criterion=criterion, optimizer=optimizer, train_loader=train_loader_CON, valid_loader=valid_loader_CON, batch_size=batch_size, train_on_gpu=train_on_gpu, save_path=save_CON_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "net.load_state_dict(torch.load(save_CON_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.701\n",
      "Test accuracy: 0.468 %\n"
     ]
    }
   ],
   "source": [
    "# testing performance of our model\n",
    "test(model=net, criterion=criterion, test_loader=test_loader_CON, batch_size=batch_size, train_on_gpu=train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Extroversion prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TensorDatasets\n",
    "train_data_EXT = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y_EXT))\n",
    "valid_data_EXT = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y_EXT))\n",
    "test_data_EXT =  TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y_EXT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will shuffle the data because if we remember our data was like first 100 were Openness and the second 100 were not this might result in biasness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_EXT = DataLoader(train_data_EXT, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "valid_loader_EXT = DataLoader(valid_data_EXT, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "test_loader_EXT = DataLoader(test_data_EXT, shuffle=True, batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:torch.Size([47, 400])\n",
      "Sample Input:\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.9000e+01, 2.8310e+03,\n",
      "         5.3000e+01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0000e+01, 4.4800e+02,\n",
      "         3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3100e+02, 1.4550e+03,\n",
      "         3.1140e+03],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4200e+02, 9.6200e+02,\n",
      "         6.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.4004e+04, 1.5610e+03,\n",
      "         9.3800e+03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.3000e+01, 2.2800e+02,\n",
      "         1.1200e+02]], dtype=torch.float64)\n",
      "\n",
      "Sample Label size:torch.Size([47])\n",
      "Sample Label:\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# lets visualize a batch of our training data\n",
    "dataiter = iter(train_loader_EXT)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size:{}'.format(sample_x.size()))\n",
    "print('Sample Input:\\n{}\\n'.format(sample_x))\n",
    "print('Sample Label size:{}'.format(sample_y.size()))\n",
    "print('Sample Label:\\n{}'.format(sample_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the LSTM model architecture is already built before, there is no need to repeat again, we gonna just call the same model within differenr dataset, which concerns this time the Conscientiousness personality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save path to save our weights with best validation accuracy\n",
    "save_EXT_path = './models/best_validation_EXT.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf ---------> 0.721867).\t Saving model...\n",
      "Epoch: 2/4... Step: 10... Loss: 0.662397... Val Loss: 0.721867\n",
      "Epoch: 3/4... Step: 20... Loss: 0.452118... Val Loss: 0.896608\n",
      "Epoch: 4/4... Step: 30... Loss: 0.236388... Val Loss: 1.450716\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "train(model=net, criterion=criterion, optimizer=optimizer, train_loader=train_loader_EXT, valid_loader=valid_loader_EXT, batch_size=batch_size, train_on_gpu=train_on_gpu, save_path=save_EXT_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "net.load_state_dict(torch.load(save_EXT_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.697\n",
      "Test accuracy: 0.553 %\n"
     ]
    }
   ],
   "source": [
    "# testing performance of our model\n",
    "test(model=net, criterion=criterion, test_loader=test_loader_EXT, batch_size=batch_size, train_on_gpu=train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Agreeableness prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TensorDatasets\n",
    "train_data_AGR = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y_AGR))\n",
    "valid_data_AGR = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y_AGR))\n",
    "test_data_AGR =  TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y_AGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will shuffle the data because if we remember our data was like first 100 were Openness and the second 100 were not this might result in biasness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_AGR = DataLoader(train_data_AGR, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "valid_loader_AGR = DataLoader(valid_data_AGR, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "test_loader_AGR = DataLoader(test_data_AGR, shuffle=True, batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:torch.Size([47, 400])\n",
      "Sample Input:\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.3200e+02, 1.2050e+03,\n",
      "         1.1080e+03],\n",
      "        [1.0000e+00, 8.8000e+01, 6.1000e+01,  ..., 1.1520e+03, 1.1520e+03,\n",
      "         2.4200e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.9000e+01, 3.4990e+03,\n",
      "         7.6300e+02],\n",
      "        ...,\n",
      "        [1.7995e+04, 7.0000e+00, 1.2200e+02,  ..., 6.5300e+02, 7.2000e+02,\n",
      "         4.3100e+02],\n",
      "        [1.6550e+03, 8.3000e+01, 1.8900e+02,  ..., 9.7800e+02, 1.5740e+03,\n",
      "         3.2100e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.9900e+02, 1.7430e+03,\n",
      "         6.9000e+01]], dtype=torch.float64)\n",
      "\n",
      "Sample Label size:torch.Size([47])\n",
      "Sample Label:\n",
      "tensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# lets visualize a batch of our training data\n",
    "dataiter = iter(train_loader_AGR)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size:{}'.format(sample_x.size()))\n",
    "print('Sample Input:\\n{}\\n'.format(sample_x))\n",
    "print('Sample Label size:{}'.format(sample_y.size()))\n",
    "print('Sample Label:\\n{}'.format(sample_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the LSTM model architecture is already built before, there is no need to repeat again, we gonna just call the same model within differenr dataset, which concerns this time the Conscientiousness personality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save path to save our weights with best validation accuracy\n",
    "save_AGR_path = './models/best_validation_AGR.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf ---------> 0.736247).\t Saving model...\n",
      "Epoch: 2/4... Step: 10... Loss: 0.532577... Val Loss: 0.736247\n",
      "Epoch: 3/4... Step: 20... Loss: 0.345809... Val Loss: 0.826437\n",
      "Epoch: 4/4... Step: 30... Loss: 0.170313... Val Loss: 1.058094\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "train(model=net, criterion=criterion, optimizer=optimizer, train_loader=train_loader_AGR, valid_loader=valid_loader_AGR, batch_size=batch_size, train_on_gpu=train_on_gpu, save_path=save_AGR_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "net.load_state_dict(torch.load(save_AGR_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.666\n",
      "Test accuracy: 0.617 %\n"
     ]
    }
   ],
   "source": [
    "# testing performance of our model\n",
    "test(model=net, criterion=criterion, test_loader=test_loader_AGR, batch_size=batch_size, train_on_gpu=train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Neuroticism prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TensorDatasets\n",
    "train_data_NEU = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y_NEU))\n",
    "valid_data_NEU = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y_NEU))\n",
    "test_data_NEU =  TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y_NEU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will shuffle the data because if we remember our data was like first 100 were Openness and the second 100 were not this might result in biasness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_NEU = DataLoader(train_data_NEU, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "valid_loader_NEU = DataLoader(valid_data_NEU, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "test_loader_NEU = DataLoader(test_data_NEU, shuffle=True, batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:torch.Size([47, 400])\n",
      "Sample Input:\n",
      "tensor([[5.5800e+02, 1.0000e+00, 4.2270e+03,  ..., 2.0000e+02, 4.3900e+02,\n",
      "         4.3290e+03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.1200e+02, 5.2000e+01,\n",
      "         4.1000e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0000e+00, 1.6740e+03,\n",
      "         6.4800e+02],\n",
      "        ...,\n",
      "        [3.1000e+01, 2.7800e+02, 5.7900e+02,  ..., 4.0160e+03, 3.0890e+03,\n",
      "         5.5810e+03],\n",
      "        [4.3600e+02, 5.2700e+02, 5.3000e+01,  ..., 1.1790e+03, 1.0050e+03,\n",
      "         5.0930e+03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4510e+03, 7.2000e+01,\n",
      "         2.3500e+02]], dtype=torch.float64)\n",
      "\n",
      "Sample Label size:torch.Size([47])\n",
      "Sample Label:\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# lets visualize a batch of our training data\n",
    "dataiter = iter(train_loader_NEU)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size:{}'.format(sample_x.size()))\n",
    "print('Sample Input:\\n{}\\n'.format(sample_x))\n",
    "print('Sample Label size:{}'.format(sample_y.size()))\n",
    "print('Sample Label:\\n{}'.format(sample_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the LSTM model architecture is already built before, there is no need to repeat again, we gonna just call the same model within differenr dataset, which concerns this time the Conscientiousness personality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save path to save our weights with best validation accuracy\n",
    "save_NEU_path = './models/best_validation_NEU.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf ---------> 0.695801).\t Saving model...\n",
      "Epoch: 2/4... Step: 10... Loss: 0.696556... Val Loss: 0.695801\n",
      "Validation loss decreased (0.695801 ---------> 0.677939).\t Saving model...\n",
      "Epoch: 3/4... Step: 20... Loss: 0.627210... Val Loss: 0.677939\n",
      "Validation loss decreased (0.677939 ---------> 0.676995).\t Saving model...\n",
      "Epoch: 4/4... Step: 30... Loss: 0.459556... Val Loss: 0.676995\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "train(model=net, criterion=criterion, optimizer=optimizer, train_loader=train_loader_NEU, valid_loader=valid_loader_NEU, batch_size=batch_size, train_on_gpu=train_on_gpu, save_path=save_NEU_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "net.load_state_dict(torch.load(save_NEU_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.726\n",
      "Test accuracy: 0.489 %\n"
     ]
    }
   ],
   "source": [
    "# testing performance of our model\n",
    "test(model=net, criterion=criterion, test_loader=test_loader_NEU, batch_size=batch_size, train_on_gpu=train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th scope=\"col\">Personality</th>\n",
    "      <th scope=\"col\">Accuracy</th>\n",
    "      <th scope=\"col\">loss value</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td scope=\"row\">Openness</td>\n",
    "      <td>57.4%</td>\n",
    "      <td>0.688</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td scope=\"row\">Conscientiousness</td>\n",
    "      <td>46.8%</td>\n",
    "      <td>0.701</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td scope=\"row\">Extroversion</td>\n",
    "      <td>69.7%</td>\n",
    "      <td>0.553</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td scope=\"row\">Agreeableness</td>\n",
    "      <td>66.6%</td>\n",
    "      <td>0.617</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td scope=\"row\">Neuroticism</td>\n",
    "      <td>48.9%</td>\n",
    "      <td>0.726</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based the table above, we can conclude that the LSTM results and metrics are somehow better tha the one done by SVM in the previous notebook, and this is due to the highest performance of Deep Learning architectures such as LSTM on similar tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the 5 built-in models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a pipeline that takes an essay and predicts the personalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, we will build a function that will preprocess a given essay. It will perform tokenization, cleaning, stopwords removal and finally pad the review.\n",
    "\n",
    "* Second, we will prepare a function that takes a review and outputs a dictionary of personalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stopwords list\n",
    "stoplist = stopwords.words('dutch') \n",
    "# get list of punctuations\n",
    "punctuations = string.punctuation + \"@\"\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    This function preprocess a given raw text by removing the retext handler, urls, mentions,\n",
    "    punctuations, stop words, numbers and emojies\n",
    "    \n",
    "    @param text string\n",
    "    @return text string\n",
    "    \"\"\"\n",
    "        \n",
    "    # string to lowercase\n",
    "    txt = text.lower()\n",
    "    \n",
    "    # keep only ascii characters\n",
    "    txt = re.sub(r\"[^a-zA-Z-]\", \" \", txt)\n",
    "    \n",
    "    # punctuation removal and map it to space\n",
    "    translator = str.maketrans(punctuations, \" \"*len(punctuations))\n",
    "    s = txt.translate(translator)\n",
    "    \n",
    "    # remove digits \n",
    "    no_digits = ''.join([i for i in s if not i.isdigit()])\n",
    "    cleaner = \" \".join(no_digits.split())\n",
    "    \n",
    "    # tokenize words and removing stop words \n",
    "    word_tokens = word_tokenize(cleaner)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stoplist]\n",
    "    filtered_sentence = \" \".join(filtered_sentence)\n",
    "    \n",
    "    # a stemming word block\n",
    "    filtered_sentence = [stemmer.stem(word) for word in word_tokenize(filtered_sentence)]\n",
    "    filtered_sentence = \" \".join(filtered_sentence)\n",
    "    \n",
    "    # 4. encoding review using our list of words that we generated earler\n",
    "    encoded_review = [word_to_index[word] for word in filtered_sentence.split() if word in word_to_index]\n",
    "    \n",
    "    return encoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 9.7000e+01 2.6500e+02 1.4166e+04 5.2000e+02\n",
      "  2.1520e+03 2.3800e+02 1.4000e+01 1.5800e+02 7.9990e+03 4.7460e+03\n",
      "  8.9000e+01 4.0000e+01 3.6000e+01 3.9900e+02 6.2300e+02 1.0530e+03\n",
      "  2.3120e+03 1.6400e+02 5.2000e+02 9.5300e+02 1.4200e+02 5.8000e+01\n",
      "  2.4860e+03 2.0000e+00 1.7700e+02 6.2300e+02 1.0530e+03 2.5600e+02\n",
      "  2.1750e+03 8.8900e+02 2.0000e+00 1.4167e+04 1.5190e+03 3.1580e+03\n",
      "  2.0000e+00 3.3100e+02 1.4168e+04 9.4400e+03 7.3570e+03 2.2900e+02\n",
      "  8.8800e+02 5.8200e+03 3.3270e+03 1.1500e+02 1.3080e+03 7.3580e+03\n",
      "  1.6400e+02 2.4700e+02 7.2400e+02 8.8800e+02 1.0530e+03 9.5300e+02\n",
      "  2.1520e+03 2.4360e+03 4.1700e+02 4.1400e+02 9.8200e+02 3.8300e+02\n",
      "  3.2050e+03 8.8800e+02 3.6500e+02 1.4169e+04 3.1580e+03 3.3780e+03\n",
      "  7.0000e+01 2.2900e+02 8.8800e+02 5.1000e+01 1.0050e+03 6.0610e+03\n",
      "  5.7000e+01 5.9500e+02 9.5300e+02 2.4730e+03 7.3570e+03 3.6050e+03\n",
      "  3.7000e+01 1.6200e+02 8.8800e+02 4.3600e+02 4.3800e+02 9.4410e+03\n",
      "  5.2440e+03 3.1400e+02 5.0500e+02 2.9630e+03 1.7700e+02 6.2300e+02\n",
      "  1.0530e+03 3.2050e+03 8.8800e+02 1.2540e+03 1.7760e+03 1.0000e+00\n",
      "  2.1880e+03 3.7430e+03 2.7000e+02 8.8900e+02 2.2900e+02 8.8800e+02\n",
      "  4.4200e+03 3.3600e+02 4.1700e+02 5.2000e+02 2.9000e+01 1.7700e+02\n",
      "  6.2300e+02 1.0530e+03 5.6460e+03 6.0000e+01 2.1600e+02 3.1920e+03\n",
      "  2.9800e+02 1.1700e+02 2.6700e+02 1.0000e+00 1.9600e+02 5.1400e+02\n",
      "  3.7400e+02 9.5400e+02 3.5500e+02 9.5300e+02 2.1520e+03 1.2500e+02\n",
      "  1.2100e+02 3.3800e+02 2.1520e+03 8.0500e+02 9.4420e+03 8.9300e+02\n",
      "  8.6300e+02 2.1520e+03 1.5640e+03 6.8000e+01 4.6800e+02 2.1520e+03\n",
      "  8.9300e+02 6.0000e+01 2.3200e+02 7.3590e+03 7.3600e+03 2.6800e+03\n",
      "  8.0500e+02 1.2910e+03 2.8640e+03 5.2000e+02 1.0530e+03 1.3240e+03\n",
      "  2.7000e+01 1.2800e+02 4.1400e+02 1.2800e+02 2.8640e+03 1.6000e+01\n",
      "  9.5300e+02 2.3500e+02 1.6000e+01 1.5000e+02 1.8000e+01 1.2500e+03\n",
      "  7.8000e+01 8.3900e+02 5.0000e+00 2.4730e+03 3.1580e+03 7.2000e+01\n",
      "  7.9200e+02 3.6000e+01 7.9970e+03 3.3600e+02 5.4900e+02 1.6000e+01\n",
      "  6.1170e+03 2.3870e+03 3.1580e+03 2.3200e+02 7.2000e+01 6.1170e+03\n",
      "  2.4200e+02 6.0000e+01 4.5600e+02 5.4900e+02 3.1580e+03 8.0500e+02\n",
      "  8.8800e+02 3.7700e+02 5.8000e+01 2.0000e+00 1.0530e+03 4.9900e+02\n",
      "  5.8000e+01 9.5300e+02 2.4730e+03 9.2200e+02 8.3000e+01 1.7980e+03\n",
      "  1.0670e+03 1.5930e+03 8.9300e+02 8.3500e+02 5.8000e+01 2.4860e+03\n",
      "  2.5900e+02 2.1520e+03 1.4170e+04 2.9700e+02 7.3000e+01 6.8000e+01\n",
      "  1.4171e+04 1.7510e+03 2.3880e+03 9.1500e+02 2.4000e+01 8.9300e+02\n",
      "  9.5300e+02 6.0000e+01 4.5600e+02 1.1100e+02 8.9300e+02 2.5850e+03\n",
      "  4.8000e+01 8.3000e+01 9.1500e+02 5.4900e+02 1.2300e+02 3.7000e+01\n",
      "  5.4800e+02 4.4780e+03 5.2050e+03 4.0100e+03 7.3000e+01 1.9390e+03\n",
      "  2.3880e+03 9.4430e+03 1.0900e+03 5.4900e+02 3.8260e+03 3.2400e+02\n",
      "  1.1100e+02 2.1380e+03 9.5300e+02 6.1170e+03 2.7000e+01 1.2800e+02\n",
      "  2.0530e+03 7.3610e+03 6.2300e+02 1.0530e+03 5.0000e+00 1.1700e+02\n",
      "  7.3590e+03 7.3600e+03 1.4172e+04 9.4430e+03 5.0000e+00 1.7240e+03\n",
      "  6.1170e+03 9.5300e+02 7.9000e+01 4.5210e+03 6.8300e+02 5.8590e+03\n",
      "  7.3620e+03 7.3630e+03 9.8000e+01 1.0900e+03 5.1610e+03 6.8300e+02\n",
      "  1.8170e+03 2.5100e+02 1.0530e+03 5.9000e+01 7.3590e+03 7.3600e+03\n",
      "  3.0200e+02 8.8000e+01 1.0000e+00 6.8300e+02 3.8400e+02 5.2000e+02\n",
      "  2.6500e+02 2.9400e+02 2.5680e+03 2.4200e+02 6.0000e+01 4.3800e+02\n",
      "  1.0490e+03 5.2000e+02 1.1800e+02 8.0500e+02 1.2910e+03 5.9130e+03\n",
      "  9.5300e+02 1.9030e+03 1.2800e+02 9.4440e+03 1.9900e+02 3.1960e+03\n",
      "  9.5300e+02 1.9030e+03 1.8820e+03 3.8900e+02 6.8300e+02 6.2300e+02\n",
      "  1.0530e+03 1.8170e+03 2.5100e+02 2.1200e+02 9.5300e+02 1.9030e+03\n",
      "  3.0200e+02 8.9000e+01 2.8310e+03 5.3000e+01]]\n"
     ]
    }
   ],
   "source": [
    "test_essay = \"\"\"\n",
    "Geen geld terug bij teerlongen\n",
    "Een patint met longkanker krijgt vaak hoge ziekenhuisrekeningen voorgeschoteld. Gelukkig kan hij, in een land als Belgi, rekenen op een medische terugbetaling. Maar achteraf blijkt dat de patint een roker is. Sommigen vinden het oneerlijk dat deze mensen ook recht hebben op medische terugbetaling. Dezelfde opinie heerst bij mensen over alchoholici die lijden aan levercirrose. Hebben deze mensen gelijk of prediken zij onzin? \n",
    "Uit een enqute bij Belgische artsen van de Vlekho Business School in samenwerking met de Artsenkrant, blijkt dat drie op tien artsen de terugbetaling van rokers met longkanker overbodig vindt. Hierbij denkt ook ongeveer een kwart van de artsen hetzelfde over alcholici met levercirrose. Een significant aantal Belgische artsen staat blijkbaar onverschillig ten opzichte van rokers en alcoholici. De enqute legde ook een ander voorbeeld voor. De artsen moesten bepalen of een bromfietser die zonder helm valt en daardoor blind wordt, recht heeft op medische terugbetaling. Een kwart van de artsen vond van niet. \n",
    "Uit deze statistieken kunnen we afleiden dat er geen overkoepelende mening heerst bij Belgische artsen. Alhoewel de meerderheid vindt dat deze patinten nog steeds recht hebben op medische terugbetaling, is de tegenstand zeker niet klein. Om een duidelijker beeld te geven van de situatie, kunnen we best de argumenten van beide standpunten vergelijken. \n",
    "Bij rokers met longkanker denken de meesten meteen dat de longkanker veroorzaakt werd door de tabak. Roken kan zonder twijfel longkanker veroorzaken, maar in alle gevallen van longkanker is roken zeker niet de oorzaak. Zo kan bij een rokende longkankerpatint zijn kanker niet veroorzaakt zijn door zijn verslaving. Oordelen of deze patint terugbetaling verdient of niet wordt dan heel moeilijk. Hierbij is het ook moeilijk oordelen wanneer je een roker bent en wanneer niet. Dit zijn feiten die eerst grondig bepaald en onderzocht moeten worden. Bij alcoholici met levercirrose wordt het zelfs nog moeilijker. In Belgi consumeert een meerderheid alcohol, maar wanneer ben je een alcoholicus? Daarbovenop kan levercirrose ook andere oorzaken hebben en kan je, zelfs bij een alcoholicus, nooit met 100% zekerheid verklaren dat alcohol de levercirrose heeft veroorzaakt. \n",
    "De artsen die daarentegen vinden dat deze mensen geen terugbetaling verdienen, vinden dat rokers en alcoholici deze aandoeningen aan hun eigen te danken hebben. Ze zijn tenslotte zelf begonnen met roken en drinken. Ze vinden het oneerlijk tegenover de andere longkanker- of levercirrosepatinten. Tegenwoordig staan op alle pakjes sigaretten waarschuwingen over de risico's van roken. Rokers kunnen zeker niet verklaren dat ze de gevolgen van roken niet kenden. Ze gebruiken het ook op eigen risico. Bij alcohol is het weer een ander verhaal. Op de verpakking van alcoholische dranken staan nergens waarschuwingen over leveraandoeningen. Iemand kan daarmee alcohol consumeren zonder bewust te zijn van de gevolgen. \n",
    "Iemand definiren als een roker of alcoholicus is heel moeilijk. Vooraleer ziekenfondsen geen medische terugbetalingen meer moeten geven aan rokende longkankerpatinten of aloholici met een leveraandoening, moeten de begrippen 'alcoholicus' en 'roker' duidelijk gedefinieerd worden. Dit is onmogelijk en zou voor een nachtmerrie van berekeningen en papierwerk zorgen. Het is daarmee juridisch onmogelijk om een stop te zetten op de terugbetaling van bijvoorbeeld rokende longkankerpatinten. \n",
    "Uiteindelijk zien we dat het onmogelijk is om deze specifieke patinten niet meer terug te betalen. Een arts kan nooit met 100% zekerheid bepalen of de ziekte van de patint echt veroorzaakt is door zijn verslaving. Ook iemand bestempelen als roker of alcoholist is moeilijk, omdat er geen parameters bestaan waarbinnen iemand een roker of alcoholist is. Realistisch gezien is het onmogelijk om deze medische terugbetalingen stop te zetten, waardoor rokers en alcoholisten uiteindelijk als de gelukkigen uit de bus komen. \n",
    "\"\"\"\n",
    "preprocessed_text = preprocess_text(test_essay)\n",
    "print(pad_features([preprocessed_text], 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_sub_classes(pred):\n",
    "    \"\"\"\n",
    "    This function will return the personality sub class from a given prediction\n",
    "    \"\"\"\n",
    "    if pred > 0 and pred <= 0.2:\n",
    "        return \"very low\"\n",
    "    elif pred > 0.2 and pred <= 0.4:\n",
    "        return \"low\"\n",
    "    elif pred > 0.4 and pred <= 0.6:\n",
    "        return \"medium\"\n",
    "    elif pred > 0.6 and pred <= 0.8:\n",
    "        return \"high\"\n",
    "    else:\n",
    "        return \"very high\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_personality_prediction(model_path, feature_tensor):\n",
    "    # Initializing the five saved models from the main LSTM model class `PersonalityLSTM`\n",
    "    model = PersonalityLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "    \n",
    "    # Loading Openness trained model from .pt file\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    batch_size = feature_tensor.size(0)\n",
    "    \n",
    "    # initialize the hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "    \n",
    "    # get the outputfrom the model\n",
    "    output, h = model(feature_tensor, h)\n",
    "    pred_value = output[0].item()\n",
    "    \n",
    "    return (round(pred_value, 4), get_predictions_sub_classes(pred_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_five_personality_traits(essay):\n",
    "    \"\"\"\n",
    "    It will return the predicted personalities from the given essay as predicted by our model\n",
    "    \"\"\"\n",
    "    \n",
    "    # process and tokenize the review using `process_review` function\n",
    "    essay = preprocess_text(essay)\n",
    "    \n",
    "    # pad pad_featuresokenized review\n",
    "    features = pad_features([essay], 400)\n",
    "\n",
    "    # convert this numpy array to tensor ttorch.from_numpythe model\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "\n",
    "    batch_size = feature_tensor.size(0)\n",
    "    \n",
    "    # Initializing the five saved models from the main LSTM model class `PersonalityLSTM`\n",
    "    model_OPN = model_CON = model_EXT = model_AGR = model_NEU = PersonalityLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "    \n",
    "    # get the models predictions\n",
    "    OPN_value = get_personality_prediction(save_OPN_path, feature_tensor)\n",
    "    CON_value = get_personality_prediction(save_CON_path, feature_tensor)\n",
    "    EXT_value = get_personality_prediction(save_EXT_path, feature_tensor)\n",
    "    AGR_value = get_personality_prediction(save_AGR_path, feature_tensor)\n",
    "    NEU_value = get_personality_prediction(save_NEU_path, feature_tensor)\n",
    "    \n",
    "    # build the final dictioanry with prediction\n",
    "    final_prediction = {\n",
    "        \"Openness\": OPN_value,\n",
    "        \"Conscientiousness\": CON_value,\n",
    "        \"Extroversion\": EXT_value,\n",
    "        \"Agreeableness\": AGR_value,\n",
    "        \"Neuroticism\": NEU_value\n",
    "    }\n",
    "    \n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Openness': (0.5231, 'medium'),\n",
       " 'Conscientiousness': (0.5378, 'medium'),\n",
       " 'Extroversion': (0.5487, 'medium'),\n",
       " 'Agreeableness': (0.2483, 'low'),\n",
       " 'Neuroticism': (0.5338, 'medium')}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_five_personality_traits(test_essay)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
